{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Berger machine translation example\n",
    "\n",
    "Machine translation example -- English to French -- from the paper 'A\n",
    "maximum entropy approach to natural language processing' by Berger et\n",
    "al., 1996.\n",
    "\n",
    "Consider the translation of the English word 'in' into French.  We\n",
    "notice in a corpus of parallel texts the following facts:\n",
    "\n",
    "    (1)    p(dans) + p(en) + p(à) + p(au cours de) + p(pendant) = 1\n",
    "    (2)    p(dans) + p(en) = 3/10\n",
    "    (3)    p(dans) + p(à)  = 1/2\n",
    "\n",
    "This code finds the probability distribution with maximal entropy\n",
    "subject to these constraints.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import maxentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f0(x):\n",
    "    return x in samplespace\n",
    "\n",
    "def f1(x):\n",
    "    return x=='dans' or x=='en'\n",
    "\n",
    "def f2(x):\n",
    "    return x=='dans' or x=='à'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [f0, f1, f2]\n",
    "\n",
    "samplespace = ['dans', 'en', 'à', 'au cours de', 'pendant']\n",
    "\n",
    "# Now set the desired feature expectations\n",
    "target_expectations = [1.0, 0.3, 0.5]\n",
    "\n",
    "X = np.atleast_2d(target_expectations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "smallmodel = maxentropy.MinDivergenceModel(features, samplespace,\n",
    "                                           vectorized=False,\n",
    "                                           verbose=False,\n",
    "                                           algorithm='BFGS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinDivergenceModel(algorithm='BFGS',\n",
       "                   features=[<function f0 at 0x10149789d8>,\n",
       "                             <function f1 at 0x1014978950>,\n",
       "                             <function f2 at 0x1a150b3bf8>],\n",
       "                   matrix_format='csr_matrix', prior_log_pdf=None,\n",
       "                   samplespace=['dans', 'en', 'à', 'au cours de', 'pendant'],\n",
       "                   vectorized=False, verbose=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "smallmodel.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How well are the constraints satisfied?\n",
    "assert np.allclose(X[0, :], smallmodel.expectations())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually test if the constraints are satisfied:\n",
    "p = smallmodel.probdist()\n",
    "assert np.isclose(p.sum(), target_expectations[0])\n",
    "assert np.isclose(p[0] + p[1], target_expectations[1])\n",
    "assert np.isclose(p[0] + p[2], target_expectations[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitted model parameters are:\n",
      "[-9.48248421e-16 -5.24869390e-01  4.87527727e-01]\n",
      "\n",
      "Fitted distribution is:\n",
      "\tx = dans           : p(x) = 0.1859\n",
      "\tx = en             : p(x) = 0.1141\n",
      "\tx = à              : p(x) = 0.3141\n",
      "\tx = au cours de    : p(x) = 0.1929\n",
      "\tx = pendant        : p(x) = 0.1929\n"
     ]
    }
   ],
   "source": [
    "# Output the distribution\n",
    "print(\"\\nFitted model parameters are:\\n\" + str(smallmodel.params))\n",
    "print(\"\\nFitted distribution is:\")\n",
    "for j, x in enumerate(smallmodel.samplespace):\n",
    "    print(f\"\\tx = {x:15s}: p(x) = {p[j]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Desired constraints:\n",
      "\tp['dans'] + p['en'] = 0.3\n",
      "\tp['dans'] + p['à']  = 0.5\n",
      "\n",
      "Actual expectations under the fitted model:\n",
      "\tp['dans'] + p['en'] = 0.29999999965207746\n",
      "\tp['dans'] + p['à']  = 0.4999999981007823\n"
     ]
    }
   ],
   "source": [
    "# Now show how well the constraints are satisfied:\n",
    "print()\n",
    "print(\"Desired constraints:\")\n",
    "print(\"\\tp['dans'] + p['en'] = 0.3\")\n",
    "print(\"\\tp['dans'] + p['à']  = 0.5\")\n",
    "print()\n",
    "print(\"Actual expectations under the fitted model:\")\n",
    "print(\"\\tp['dans'] + p['en'] =\", p[0] + p[1])\n",
    "print(\"\\tp['dans'] + p['à']  =\", p[0] + p[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulated version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `maxentropy` package supports simulation for estimating continuous models or discrete ones that are too large to enumerate (e.g. for whole sentences in a natural language).\n",
    "\n",
    "Here we repeat the above example with simulation. The problem is tiny but we demonstrate how to use simulation conceptually and the API differences when using simulation with `maxentropy` versus with small discrete models.\n",
    "\n",
    "The following code finds the probability distribution with maximal entropy subject to the same constraints as above **without enumerating the sample space**, using importance sampling instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from maxentropy.utils import dictsampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f0(x):\n",
    "    return x in samplespace\n",
    "\n",
    "def f1(x):\n",
    "    return x == 'dans' or x == 'en'\n",
    "\n",
    "def f2(x):\n",
    "    return x == 'dans' or x == 'à'\n",
    "\n",
    "f = [f0, f1, f2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a uniform instrumental distribution for sampling\n",
    "samplefreq = {e: 1 for e in samplespace}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "auxiliary_sampler = dictsampler(samplefreq, size=10**5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['à', 'pendant', 'pendant', ..., 'pendant', 'en', 'dans'],\n",
       "       dtype=object),\n",
       " array([-1.60943791, -1.60943791, -1.60943791, ..., -1.60943791,\n",
       "        -1.60943791, -1.60943791]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(auxiliary_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigmodel = maxentropy.MCMinDivergenceModel(f, auxiliary_sampler,\n",
    "                                           vectorized=False,\n",
    "                                           verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now set the desired feature expectations\n",
    "target_expectations = [1.0, 0.3, 0.5]\n",
    "\n",
    "X = np.atleast_2d(target_expectations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MCMinDivergenceModel(algorithm='CG',\n",
       "                     auxiliary_sampler=<method-wrapper '__next__' of generator object at 0x1a1548b408>,\n",
       "                     feature_functions=None, matrix_format='csc_matrix',\n",
       "                     prior_log_pdf=None, vectorized=None, verbose=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigmodel.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted model parameters are:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 8.28032816e-12, -5.14381304e-01,  4.78186108e-01])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output the true distribution\n",
    "print(\"Fitted model parameters are:\")\n",
    "bigmodel.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use discrete model fitted above to evaluate how good these fitted parameters are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "smallmodel.setparams(bigmodel.params)\n",
    "p = smallmodel.probdist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitted distribution is:\n",
      "\tx = dans           : p(x) = 0.1864\n",
      "\tx = en             : p(x) = 0.1155\n",
      "\tx = à              : p(x) = 0.3117\n",
      "\tx = au cours de    : p(x) = 0.1932\n",
      "\tx = pendant        : p(x) = 0.1932\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFitted distribution is:\")\n",
    "for j, x in enumerate(samplespace):\n",
    "    print(f\"\\tx = {x:15s}: p(x) = {p[j]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Desired constraints:\n",
      "\tp['dans'] + p['en'] = 0.3\n",
      "\tp['dans'] + p['à']  = 0.5\n",
      "\n",
      "Actual expectations under the fitted model:\n",
      "\tp['dans'] + p['en'] = 0.3019\n",
      "\tp['dans'] + p['à']  = 0.4980\n"
     ]
    }
   ],
   "source": [
    "# Now show how well the constraints are satisfied:\n",
    "print()\n",
    "print(\"Desired constraints:\")\n",
    "print(\"\\tp['dans'] + p['en'] = 0.3\")\n",
    "print(\"\\tp['dans'] + p['à']  = 0.5\")\n",
    "print()\n",
    "print(\"Actual expectations under the fitted model:\")\n",
    "print(f\"\\tp['dans'] + p['en'] = {p[0] + p[1]:.4f}\")\n",
    "print(f\"\\tp['dans'] + p['à']  = {p[0] + p[2]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Estimated error in constraint satisfaction (should be close to 0):\n",
      " [[8.10462808e-14 1.72560798e-08 1.16287774e-08]]\n",
      "\n",
      "True error in constraint satisfaction (should be close to 0):\n",
      " [[0.         0.00187074 0.00195854]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nEstimated error in constraint satisfaction (should be close to 0):\\n\",\n",
    "        abs(bigmodel.expectations() - X))\n",
    "print(\"\\nTrue error in constraint satisfaction (should be close to 0):\\n\",\n",
    "        abs(smallmodel.expectations() - X))"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
