{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting large maximum entropy models with simulation - Berger machine translation example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here is an example with simulation on a tiny problem\n",
    "\n",
    "It demonstrates how to use simulation conceptually and the API of `maxentropy`.\n",
    "\n",
    "As in `example_berger.py`, this is the machine translation example\n",
    "-- English to French -- from the paper 'A maximum entropy approach\n",
    "to natural language processing' by Berger et\n",
    "al., 1996.\n",
    "\n",
    "Consider the translation of the English word 'in' into French.  We\n",
    "notice in a corpus of parallel texts the following facts:\n",
    "\n",
    "    (1)    p(dans) + p(en) + p(à) + p(au cours de) + p(pendant) = 1\n",
    "    (2)    p(dans) + p(en) = 3/10\n",
    "    (3)    p(dans) + p(à)  = 1/2\n",
    "\n",
    "This code finds the probability distribution with maximal entropy\n",
    "subject to these constraints **without enumerating the sample space**,\n",
    "using importance sampling instead.\n",
    "\n",
    "This is way overkill for this tiny problem (which can be solved analytically),\n",
    "but it demonstrates how to use simulation in principle to solve larger problems\n",
    "on a continuous or larger discrete sample space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "\n",
    "import maxentropy\n",
    "from maxentropy.maxentutils import dictsampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "samplespace = ['dans', 'en', 'à', 'au cours de', 'pendant']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@np.vectorize\n",
    "def f0(x):\n",
    "    return x in samplespace\n",
    "\n",
    "@np.vectorize\n",
    "def f1(x):\n",
    "    return x == 'dans' or x == 'en'\n",
    "\n",
    "@np.vectorize\n",
    "def f2(x):\n",
    "    return x == 'dans' or x == 'à'\n",
    "\n",
    "f = [f0, f1, f2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(True, dtype=bool)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f0('dans')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a uniform instrumental distribution for sampling\n",
    "samplefreq = {e: 1 for e in samplespace}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "auxiliary_sampler = dictsampler(samplefreq, size=10**5, return_probs='logprob')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['pendant', 'pendant', 'à', ..., 'en', 'à', 'en'], dtype=object),\n",
       " array([-1.60943791, -1.60943791, -1.60943791, ..., -1.60943791,\n",
       "        -1.60943791, -1.60943791]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(auxiliary_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = maxentropy.BigModel(auxiliary_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Default: model.algorithm = 'CG'\n",
    "# Can choose from ['CG', 'BFGS', 'LBFGSB', 'Powell', 'Nelder-Mead']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now set the desired feature expectations\n",
    "K = [1.0, 0.3, 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'importance_sampler'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-ccdc5c8c5b1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmaxentropy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxentutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimportance_sampler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_vectorized_feature_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'importance_sampler'"
     ]
    }
   ],
   "source": [
    "from maxentropy.maxentutils import importance_sampler, create_vectorized_feature_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = create_vectorized_feature_function(f, sparse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, logprobs = next(auxiliary_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.samplegen = importance_sampler(features, auxiliary_sampler)\n",
    "model.reset(len(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(model.samplegen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.resample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.verbose = True\n",
    "\n",
    "# Fit the model\n",
    "# model.avegtol = 1e-5\n",
    "model.fit(f, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the true distribution\n",
    "print(\"Fitted model parameters are:\")\n",
    "model.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smallmodel = maxentropy.Model(samplespace)\n",
    "smallmodel.setparams(model.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smallmodel.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "smallmodel.setfeatures(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smallmodel.F.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = smallmodel.F.todense().T\n",
    "F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smallmodel.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.dot(smallmodel.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smallmodel.F.T.dot(smallmodel.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nFitted distribution is:\")\n",
    "smallmodel.showdist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now show how well the constraints are satisfied:\n",
    "print()\n",
    "print(\"Desired constraints:\")\n",
    "print(\"\\tp['dans'] + p['en'] = 0.3\")\n",
    "print(\"\\tp['dans'] + p['à']  = 0.5\")\n",
    "print()\n",
    "print(\"Actual expectations under the fitted model:\")\n",
    "print(\"\\tp['dans'] + p['en'] =\", p[0] + p[1])\n",
    "print(\"\\tp['dans'] + p['à']  = \" + str(p[0]+p[2]))\n",
    "\n",
    "print(\"\\nEstimated error in constraint satisfaction (should be close to 0):\\n\"\n",
    "        + str(abs(model.expectations() - K)))\n",
    "print(\"\\nTrue error in constraint satisfaction (should be close to 0):\\n\" +\n",
    "        str(abs(smallmodel.expectations() - K)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
